~~~~~~~~~~~~~~~~~~~~~~~~ STEPS ~~~~~~~~~~~~~~~~~~~~~~~~

> Collect data in DICOM format, to ensure the model is trained on a set of unique subjects and tested on strictly unseen
  data do not include images from follow-up patient visits.
  
> Convert all the DaT SPECT images into png/jpg format to support InceptionV3 CNN.

> (Optional) Concatenate slice 40, 41, 42 into one slice. Otherwise use use slice 41.

> Use the ImageDataGenerator class from the Keras deep learning library. The ImageDataGenerator is able to load
  small batches of images on the fly, directly from their respective directories (train,
  validation and test) using the flow from directory method. (Used when system memory is limited)
  
> Because of small dataset the images need augmentations via a series of transformations. Data augmentations were 
  done on the fly,this is performed using the ImageDataGenerator class, provided by the Keras deep learning library.
  Training data underwent width shifts, height shifts, horizontal flipping and brightness augmentations.
  
> (Optional) Split dataset into 10 folds to be used for k-fold cross validation. Ensure that ratio between classes
  remains same across all folds.
  
> InceptionV3 implements a deep CNN using the Keras neural network library that is running on top of a TensorFlow backend.
  It utilized transfer learning of a pre-trained model and defined a custom, binary classifying block. 
  
> The classifying block consists of a 2D global average pooling layer taking the base model’s output as its input, 
  followed by a dense layer with ReLU activation, followed by a dropout layer, and a final dense layer with sigmoid 
  activation.
  
> This combined model was compiled using the Adam optimizer with an initial learning rate of 10^−3 and a step decay 
  function that gradually decreased the learning rate until it reached a final learning rate of 10^−6.
 
> The loss function used was binary crossentropy and the metric used to analyze the performance of the model was accuracy.

> Each model of the ten-fold cross validation was trained over 500 epochs with a batch size of 16.

> This produced a sensitivity of 0.9888, a specificity of 0.9767 and a precision of 0.9888.
  
> Apply LIME.


~~~~~~~~~~~~~~~~~~~~~~~~ TUTORIALS ~~~~~~~~~~~~~~~~~~~~~~~~

Brain Tumor Detection with Transefer Learning
// The most comprehensive tutorial
https://www.kaggle.com/loaiabdalslam/brain-tumor-mri-classification-vgg16

DICOM to JPG
// Convert .dcm images
https://www.kaggle.com/onealbao/dicom-to-jpeg-conversion-kernel
https://medium.com/@vivek8981/dicom-to-jpg-and-extract-all-patients-information-using-python-5e6dd1f1a07d

Medical Image Classification with Transfer Learning
// Tutorial
https://mc.ai/medical-image-classification-with-transfer-learning/

Transfer Learning using Inception-v3 for Image Classification
// Tutorial
https://medium.com/analytics-vidhya/transfer-learning-using-inception-v3-for-image-classification-86700411251b

Image Classification Transfer Learning with Inception v3
// Google CLoud Tutorial
https://codelabs.developers.google.com/codelabs/cpb102-txf-learning/index.html?index=..%2F..index#0

Interpretable Machine Learning with LIME for Image Classification
// LIME tutorial
https://nbviewer.jupyter.org/url/arteagac.github.io/blog/lime_image.ipynb












.
